import numpy as np
from typing import Tuple
from logging import RootLogger
from PyFHD.pyfhd_tools.pyfhd_utils import resistant_mean, weight_invert, rebin, histogram
from copy import deepcopy
from astropy.io import fits
from astropy.constants import c
from pathlib import Path
from scipy.ndimage import uniform_filter


def vis_extract_autocorr(obs: dict, vis_arr: np.array, time_average = True, auto_tile_i = None) -> Tuple[np.array, np.array]:
    """
    TODO: Docstring

    Parameters
    ----------
    obs : dict
        The dictionary generated by PyFHD containing metadata and data from the observation
    vis_arr : np.array
        The visibility array
    time_average : bool, optional
        _description_, by default True
    auto_tile_i : _type_, optional
        _description_, by default None

    Returns
    -------
    Tuple[autocorr: np.array, auto_tile_i: np.array]
        The first array is the auto-correlation visibilities and the second array is the unique tile values
    """
    # TODO: check if tile_a and tile_b 2D
    autocorr_i = np.where(obs["baseline_info"]["tile_a"] == obs["baseline_info"]["tile_b"])[0]
    if (autocorr_i[0].size > 0):
        auto_tile_i = obs["baseline_info"]["tile_a"][autocorr_i] - 1
        auto_tile_i_single = np.unique(auto_tile_i)
        auto_corr = np.zeros(obs["n_pol"])
        for pol_i in range(obs["n_pol"]):
            # TODO: check vis_arr shape again, compare against IDL
            auto_vals = vis_arr[pol_i, :, autocorr_i]
            if (time_average):
                auto_single = np.zeros([auto_tile_i_single.size, obs["n_freq"]])
                time_inds = np.where(obs["baseline_info"]["time_use"])
                for tile_i in range(time_inds[0].size):
                    baseline_i = np.where(auto_tile_i == auto_tile_i_single[tile_i])
                    baseline_i = baseline_i[time_inds]
                    if (time_inds[0].size > 1): 
                        # TODO: Check axis sum is being applied to
                        auto_single[tile_i, :] = np.sum(auto_vals[baseline_i, :][:, np.arange(obs['n_freq'])], axis = 1) / time_inds[0].size
                    else:
                        # TODO: Check Size of auto_single
                        auto_single[tile_i, :] = auto_vals[baseline_i, :][:, np.arange(obs['n_freq'])]
                auto_vals = auto_single
            # TODO: Get size of auto_vals or do a python list of numpy arrays
            auto_corr[pol_i] = auto_vals
        if (time_average):
            auto_tile_i = auto_tile_i_single
        return auto_corr, auto_tile_i
    else:
        # Return auto_corr as 0 and auto_tile_i as an empty array
        return np.zeros(1), np.zeros(0)

def vis_cal_auto_init(obs : dict, cal : dict, vis_arr: np.array, vis_model_arr: np.array, vis_auto: np.array, vis_auto_model: np.array, auto_tile_i: np.array) -> np.array:
    """
    TODO: Docstring

    Parameters
    ----------
    obs : dict
        _description_
    cal : dict
        _description_
    vis_arr : np.array
        _description_
    vis_model_arr : np.array
        _description_
    vis_auto : np.array
        _description_
    vis_auto_model : np.array
        _description_
    auto_tile_i : np.array
        _description_

    Returns
    -------
    auto_gain : np.array
        _description_
    """
    # TODO: This should be a list, or ideally an numpy array with a known shape, change this line to reflect this
    auto_scale = np.zeros(cal["n_pol"])
    freq_i_use = np.where(obs["baseline_info"]["freq_use"])
    for pol_i in range(cal["n_pol"]):
        res_mean_data = resistant_mean(vis_arr[pol_i, :, freq_i_use], 2)
        res_mean_model = resistant_mean(vis_model_arr[pol_i, :, freq_i_use], 2)
        auto_scale[pol_i] = np.sqrt(res_mean_data / res_mean_model)
    # TODO: This should be a list, or ideally an numpy array with a known shape, change this line to reflect this
    # TODO: Vectorize below loops
    auto_gain = np.zeros(cal["n_pol"], dtype=np.complex128)
    for pol_i in range(cal["n_pol"]):
        gain_arr = np.zeros([obs["n_tile"], obs["n_freq"]], dtype=np.complex128)
        for freq_i in range(obs["n_freq"]):
            for tile_i in range(auto_tile_i.size):
                # TODO: Check size of gain_single in FHD and compare against what's here
                gain_arr[auto_tile_i[tile_i], freq_i] = np.sqrt(vis_auto[pol_i, tile_i, freq_i] * weight_invert(vis_auto_model[pol_i, tile_i, freq_i]))
        gain_arr *= auto_scale[pol_i] * weight_invert(np.mean(gain_arr))
        gain_arr[np.isnan(gain_arr)] = 1
        gain_arr[np.where(gain_arr) <= 0] = 1
        auto_gain[pol_i] = gain_arr
    return auto_gain

def vis_calibration_flag(obs: dict, cal: dict, params: dict, pyfhd_config: dict, logger: RootLogger) -> dict:
    """
    TODO: Docstring

    Parameters
    ----------
    obs : dict
        _description_
    cal : dict
        _description_
    pyfhd_config : dict
        The configuration dictionary for PyFHD given at the start of the run
    logger : RootLogger
        PyFHD's logger for displaying errors and info to the log files

    Returns
    -------
    obs: dict
        _description_
    """
    amp_sigma_threshold = 5
    amp_threshold = 2
    phase_sigma_threshold = 5
    for pol_i in range(cal["n_pol"]):
        tile_use_i = np.where(obs["baseline_info"]["tile_use"])
        freq_use_i = np.where(obs["baseline_info"]["freq_use"])
        # TODO: adjust depending on size given by vis_cal_auto_init
        gain = cal["gain"][pol_i]
        phase = np.arctan2(gain.imag, gain.real)
        amp = np.abs(gain)

        # first flag based on overall amplitude
        # extract_subarray is not being used as it was FHD's way of taking the fact that
        # IDL's indexing can be weird and won't allow to index the result
        # TODO: May need to adjust the indexing to match IDL as tile_use_i and freq_use_i use np.where on gain, which will be multidimensional as well
        amp_sub = amp[tile_use_i[0],:][: , freq_use_i[0]]
        gain_freq_fom = np.std(amp_sub[:, 0: freq_use_i[0].size])
        amp_sub2 = amp_sub[tile_use_i[0], :]
        # Calculate the y values from a polynomial fit and keep the standard deviation of the error in gain_tile_fom
        amp_sub2_fit = np.polynomial.polynomial.polyval(freq_use_i[0],np.polynomial.Polynomial.fit(freq_use_i[0], amp_sub2, deg = pyfhd_config["cal_amp_degree_fit"]).convert().coef)
        gain_tile_fom = np.std(amp_sub2 - amp_sub2_fit)
        gain_tile_avg = np.median(amp_sub2)
        gain_freq_fom[np.isnan(gain_freq_fom)] = 0
        gain_tile_fom[np.isnan(gain_tile_fom)] = 0
        freq_cut_i = np.where(gain_freq_fom == 0)
        freq_uncut_i = np.nonzero(gain_freq_fom)
        if (freq_cut_i[0].size > 0):
            obs["baseline_info"]["freq_use"][freq_use_i][0][freq_cut_i] = 0
        tile_cut_i = np.where(gain_tile_fom == 0)
        tile_uncut_i = np.nonzero(gain_tile_fom)
        if (tile_cut_i[0].size > 0):
            obs["baseline_info"]["tile_use"][tile_use_i][0][tile_cut_i] = 0
        if (freq_uncut_i[0].size > 0 or tile_uncut_i[0].size):
            # TODO: Check message is correct
            logger.error("The frequency and tile flagging inside claibration found some values not detected in previous flagging or calibration")
        
        n_addl_cut = max(freq_cut_i[0].size + tile_cut_i[0].size, 1)
        n_cut = freq_cut_i[0].size + tile_cut_i[0].size
        iter = 0
        while n_addl_cut > 0 and iter < 3:
            gain_freq_sigma = np.std(gain_freq_fom[freq_uncut_i])
            gain_tile_sigma = np.std(gain_tile_fom[tile_uncut_i])
            freq_cut_test = (gain_freq_fom - np.median(gain_tile_fom[freq_uncut_i]) - amp_sigma_threshold * gain_freq_sigma) > 0
            # TODO: Check size of freq_cut_i
            freq_cut_i = np.where(freq_cut_test)
            tile_cut_test1 = (gain_tile_fom - np.median(gain_tile_fom[tile_uncut_i]) - amp_sigma_threshold * gain_tile_sigma) > 0
            tile_cut_test2 = (gain_tile_avg < np.median(gain_tile_avg) / amp_threshold) or (gain_tile_avg > np.median(gain_tile_avg) * amp_threshold)
            # TODO: Check size of tile_cut_i
            tile_cut_i = np.where(tile_cut_test1 or tile_cut_test2)
            n_addl_cut = (freq_cut_i[0].size + tile_cut_i[0]) - n_cut
            n_cut = freq_cut_i[0].size + tile_cut_i[0].size
            iter+=1
        if (freq_cut_i[0].size) > 0:
            obs["baseline_info"]["freq_use"][freq_use_i[freq_cut_i]] = 0
        if (tile_cut_i[0].size) > 0:
            obs["baseline_info"]["tile_use"][tile_use_i[tile_cut_i]] = 0

        # Reset freq_use_i and tile_use_i for flagging based on phase
        tile_use_i = np.where(obs["baseline_info"]["tile_use"])
        freq_use_i = np.where(obs["baseline_info"]["freq_use"])

        # Start flagging based on phase
        phase_sub = phase[tile_use_i[0], :][:, freq_use_i[0]]
        phase_slope_arr = np.empty(tile_use_i[0].size)
        phase_sigma_arr = np.empty(tile_use_i[0].size)
        for tile_i in range(tile_use_i[0].size):
            phase_use = np.unwrap(phase_sub[tile_i, :])
            fi_use2 = np.arange(freq_use_i[0].size)
            # TODO: Check the size, but should be a 1D array
            phase_use2 = phase_use[fi_use2]
            phase_params = np.polynomial.polynomial.Polynomial.fit(freq_use_i[fi_use2], phase_use2, deg=pyfhd_config["cal_phase_degree_fit"])
            phase_params = phase_params.convert()
            phase_fit = np.polynomial.polynomial.polyval(freq_use_i[fi_use2], phase_params.coef)
            phase_sigma2 = np.std(phase_use2 - phase_fit)
            # TODO: Check coefficients are the same shape
            phase_slope_arr[tile_i] = phase_params[1]
            phase_sigma_arr[tile_i] = phase_sigma2
        iter = 0
        n_addl_cut = 1
        n_cut = 0
        while n_addl_cut > 0 and iter < 3:
            slope_sigma = np.std(phase_slope_arr)
            tile_cut_test1 = (np.abs(phase_slope_arr) - np.median(np.abs(phase_slope_arr))) > phase_sigma_threshold * slope_sigma
            tile_cut_test2 = (phase_sigma_arr - np.median(phase_sigma_arr)) > phase_sigma_threshold * np.std(phase_sigma_arr)
            # TODO: Check size of tile_cut_i
            tile_cut_i = np.where(tile_cut_test1 or tile_cut_test2)
            n_addl_cut = tile_cut_i[0].size - n_cut
            n_cut = tile_cut_i[0].size
            iter += 1
        if (tile_cut_i[0].size > 0):
            obs["baseline_info"]["tile_use"][tile_use_i[tile_cut_i]] = 0
    # Return the obs with an updated baseline_info on the use of tiles and frequency
    return obs

def transfer_bandpass(obs: dict, params: dict, cal: dict, pyfhd_config: dict, logger: RootLogger) -> Tuple[dict, dict]:
    # TODO: Get bandpass from fits file and process the data_array
    cal_bandpass = {}
    try:  
        calfits = fits.open(Path(pyfhd_config['input_path'], pyfhd_config["cal_bp_transfer"]))
    except FileNotFoundError as e:
        logger.error(f"{pyfhd_config['cal_bp_transfer']} file wasn't found, skipping calibration bandpass transfer")
        return {}, {}
    cal_remainder = deepcopy(cal)
    cal_remainder["gain"][0 : cal["n_pol"]] = cal["gain"][0 : cal["n_pol"]] / cal_bandpass["gain"][0 : cal["n_pol"]]
    return cal_bandpass, cal_remainder

def vis_cal_bandpass(obs: dict, cal: dict, params: dict, pyfhd_config: dict, logger: RootLogger) -> Tuple[dict, dict]:
    """
    TODO: Docstring

    Parameters
    ----------
    obs : dict
        The observation data given to PyFHD
    cal : dict
        The calibration dictionary containing the data from the calibration
    params : dict
        The PyFHD params containing uu, ww, vv
    pyfhd_config : dict
        The config used to start PyFHD containing config for calibration
    logger : RootLogger
        PyFHD's logger

    Returns
    -------
    (cal_bandpass, cal_remainder) : Tuple[dict, dict]
        The bandpass gain dictonary and the remainder cable gain dictionary
    """
    freq_use = np.nonzero(obs["baseline_info"]["freq_use"])[0]
    tile_use = np.nonzero(obs["baseline_info"]["tile_use"])[0]
    n_pol = cal["gain"].size
    # Set a flag for global bandpass, will turn true if too many tiles are flagged
    global_bandpass = False

    # Initialize cal_bandpass and cal_remainder and transfer them in, if a file has been set (fits only supported right now)
    if (pyfhd_config["cal_bp_transfer"] is not None):
        # TODO: Finish transfer_bandpass (code to translate will be in calfits_read.pro)
        cal_bandpass, cal_remainder = transfer_bandpass(obs, params, cal, pyfhd_config, logger)
        if (len(cal_bandpass.keys()) != 0 and len(cal_remainder.keys()) != 0):
            logger.info(f"Calibration Bandpass FITS file {pyfhd_config['cal_bp_transfer']} transferred in for cal_bandpass and cal_remainder")
            return cal_bandpass, cal_remainder
    cal_bandpass = deepcopy(cal)
    cal_remainder = deepcopy(cal)
     # These replace gain_arr_ptr_2 & 3 from FHD with better names
    cal_bandpass_gain = np.empty(n_pol)
    cal_remainder_gain = np.empty(n_pol)

    if (pyfhd_config["cable_bandpass_fit"]):
        # Using preexisting file to extract information about which tiles have which cable length
        cable_len = np.loadtxt(Path(pyfhd_config["input"], pyfhd_config["cable-reflection-coefficients"]), skiprows=1)[:, 2].flatten()
        # Taking tile information and cross-matching it with the nonflagged tiles array, resulting in nonflagged tile arrays grouped by cable length
        cable_length_ref = np.unique(cable_len)
        tile_use_arr = [] * cable_length_ref.size
        for cable_i in range(cable_length_ref.size):
            tile_use_arr[cable_i] = np.where((obs["baseline_info"]["tile_use"]) & (cable_len == cable_length_ref[cable_i]))
            if (tile_use_arr[0].size == 0):
                logger.warning("Too Many flagged tiles to implement bandpass cable averaging, using global bandpass.")
                global_bandpass = True
        # n_freq x 13 array. columns are frequency, 90m xx, 90m yy, 150m xx, 150m yy, 230m xx, 230m yy, 320m xx, 320m yy, 400m xx, 400m yy, 524m xx, 524m yy
        bandpass_arr = np.zeros(obs["n_freq"], cal["n_pol"] * cable_length_ref.size + 1)
        bandpass_arr[:, 0] = cal["freq"]
        bandpass_col_count = 1
        if (pyfhd_config['auto_ratio_calibration']):
            logger.info('auto_ratio_calibration is set, using global bandpass')
            global_bandpass = True
        for cable_i in range(cable_length_ref.size):
            # This is an option to calibrate over all tiles to find the 'global' bandpass. It will be looped over by the number
            # of cable lengths, and will redo the same calculation everytime. It is inefficient, but effective.
            if global_bandpass:
                tile_use_cable = tile_use
            else:
                tile_use_cable = tile_use_arr[cable_i]

            for pol_i in range(cal["n_pol"]):
                gain = cal["gain"][pol_i]
                # gain2 is a temporary variable used in place of the gain array for an added layer of safety
                if (cable_i == 0 and pol_i == 0):
                    gain2 = np.zeros((gain.shape[0], gain[1], cal["n_pol"]), dtype = np.complex128)
                # Only use gains from unflagged tiles and frequencies, and calculate the amplitude and phase
                gain_use = gain[tile_use_cable,:][: , freq_use]
                amp = np.abs(gain_use)
                # amp2 is a temporary variable used in place of the amp array for an added layer of safety
                amp2 = np.zeros(tile_use_cable.size, freq_use.size)
                # This is the normalization loop for each tile. If the mean of gain amplitudes over all frequencies is nonzero, then divide
                # the gain amplitudes by that number, otherwise make the gain amplitudes zero.
                for tile_i in range(tile_use_cable.size):
                    res_mean = resistant_mean(amp[tile_i, :], 2)
                    if res_mean != 0:
                        amp2[tile_i, :] = amp[tile_i, :] / res_mean
                    else:
                        amp2[tile_i, :] = 0
                # This finds the normalized gain amplitude mean per frequency over all tiles, which is the final bandpass per cable group.
                bandpass_single = np.empty((freq_use.size, tile_use.size))
                # If this is slow, resistant_mean can be vectorized
                for f_i in range(freq_use.size):
                    bandpass_single[f_i, :] = resistant_mean(amp2[:, f_i], 2)
                # Want iterative to start at 1 (to not overwrite freq) and store final bandpass per cable group.
                bandpass_arr[freq_use, bandpass_col_count] = bandpass_single
                bandpass_col_count += 1
                # Fill temporary variable gain2, set equal to final bandpass per cable group for each tile that will use that bandpass. 
                gain2[tile_use_cable, freq_use, pol_i] = bandpass_single
                # For the last bit at the end of the cable
                if cable_i == cable_length_ref.size - 1:
                    # Set gain3 to the input gains
                    gain3 = deepcopy(cal["gain"])
                    # Set what will be passed back as the output gain as the final bandpass per cable type.
                    gain2_input = np.squeeze(gain2[:, : , pol_i])
                    cal_bandpass_gain[pol_i] = gain2_input
                    # Set what will be passed back as the residual as the input gain divided by the final bandpass per cable type.
                    gain3[0: obs["n_tile"], freq_use] /= gain2_input[0 : obs["n_tile"], freq_use]
                    cal_remainder_gain[pol_i] = gain3
        # Add Levine Memo bandpass to the gain solutions here if you wish
    else:
        for pol_i in range(cal["n_pol"]):
            gain = cal["gain"][pol_i]
            gain_use = gain[tile_use_cable,:][: , freq_use]
            amp = np.abs(gain_use)
            amp2 = np.zeros(tile_use.size, freq_use.size)
            for tile_i in range(tile_use.size):
                res_mean = resistant_mean(amp[tile_i, :], 2)
                if res_mean:
                    amp2[tile_i, : ] = amp[tile_i , : ] / res_mean
                else:
                    amp2[tile_i, : ] = 0
            bandpass_single = np.empty((freq_use.size, tile_use.size))
            # If this is slow, resistant_mean can be vectorized
            for f_i in range(freq_use.size):
                bandpass_single[f_i, :] = resistant_mean(amp2[: ,f_i], 2)
            bandpass_arr[freq_use, pol_i + 1] = bandpass_single
            # Work out the gain for the bandpass
            gain2 = np.zeros(gain.shape, dtype = np.complex128)
            gain2[0 : tile_use.size, freq_use] = bandpass_single
            cal_bandpass_gain[pol_i] = gain2
            # Work out the gain for the remaider of the cable
            gain3 = gain
            gain3[0: tile_use.size, freq_use] /= bandpass_single
            cal_remainder_gain[pol_i] = gain3
    cal_bandpass["gain"] = cal_bandpass_gain
    cal_remainder["gain"] = cal_remainder_gain
    return cal_bandpass, cal_remainder

def vis_cal_polyfit(obs: dict, cal: dict, auto_ratio: np.ndarray | None, pyfhd_config: dict, logger: RootLogger) -> dict:
    # Keep the og_gain_arr for calculations later
    og_gain_arr = cal['gain']
    if (pyfhd_config['cal_reflection_mode_theory'] or 
        pyfhd_config['cal_reflection_mode_file'] or 
        pyfhd_config['cal_reflection_mode_delay'] or
        pyfhd_config['cal_reflection_hyperresolve']
    ):
        if (pyfhd_config['cal_reflection_mode_theory'] and abs(pyfhd_config['cal_reflection_mode_theory']) > 1):
            cal_mode_fit = pyfhd_config['cal_reflection_mode_theory']
        else:
            cal_mode_fit = 1
    freq_use = np.where(obs['baseline_info']['freq_use'])
    tile_use = np.where(obs['baseline_info']['tile_use'])

    # If the amp_degree or phase_degree weren't used, then apply the defaults
    if (not pyfhd_config['cal_amp_degree_fit']):
        pyfhd_config['cal_amp_degree_fit'] = 2
    if (not pyfhd_config['cal_phase_degree_fit']):
        pyfhd_config['cal_phase_degree_fit'] = 1

    # If you wish to find any steps that are outliers beyond 5sigma, and remove them add that code here.
    # The cal_step_fit option isn't in the eor_defaults_wrapper or defined in the FHD dictionary.

    # Polynomial fitting over the frequency band
    gain_residual = np.empty((obs['n_tile'], cal['n_pol']))
    # create amp_params with the shape of (n_pol, n_tile, amp_degree + 1)
    cal['amp_params'] = np.empty((cal['n_pol'], obs['n_tile'], pyfhd_config["cal_amp_degree_fit"] + 1))
    cal['phase_params'] = np.empty((cal['n_pol'], obs['n_tile'], pyfhd_config["cal_phase_degree_fit"] + 1))
    for pol_i in range(cal['n_pol']):
        gain_arr = cal['gain'][pol_i]
        gain_amp = np.abs(gain_arr)
        gain_phase = np.arctan2(gain_arr.imag, gain_arr.real)
        for tile_i in range(obs['n_tile']):
            gain = np.squeeze(gain_amp[tile_i, freq_use])
            # Fit for amplitude
            fit_params = np.polynomial.Polynomial.fit(freq_use, gain, deg = pyfhd_config["cal_amp_degree_fit"]).convert().coef
            cal['amp_params'][pol_i, tile_i, :] = fit_params
            gain_fit = np.zeros(obs['n_freq'])
            # Pre and post digital gain jump separately for highband MWA data
            if (pyfhd_config['digital_gain_jump_polyfit']):
                pre_dig_inds = np.where(obs['baseline_info']['freq'][freq_use] < 187.515e6)
                if pre_dig_inds[0].size == 0:
                    f_d = np.max(pre_dig_inds[0])
                    f_end = freq_use[0].size
                    fit_params1 = np.polynomial.Polynomial.fit(freq_use[0: f_d], gain[0:f_d], pyfhd_config['cal_amp_degree_fit'] - 1).convert().coef
                    fit_params2 = np.polynomial.Polynomial.fit(freq_use[f_d + 1: f_end], gain[f_d + 1: f_end], pyfhd_config['cal_amp_degree_fit']).convert().coef
                    for di in range(pyfhd_config['cal_amp_degree_fit']):
                        gain_fit[freq_use[0] : freq_use[f_d]] += fit_params1[di] * (np.arange(freq_use[f_d]) ** di)
                        gain_fit[freq_use[f_d + 1] : freq_use[f_end]] += fit_params2[di] * (np.arange(freq_use[f_end] - freq_use[f_d + 1] + 1) + freq_use[f_d + 1])**di
                    fit_params = [fit_params1, fit_params2]
                    cal['amp_params'][pol_i, tile_i] = fit_params
                else:
                    logger.warning('digital_gain_jump_polyfit only works with highband mwa data. Full band polyfit applied instead.')
            else: 
                for di in range(pyfhd_config['cal_amp_degree_fit']):
                    gain_fit += fit_params[di, :, :] * np.arange(obs['n_freq'])**di
            
            # TODO: Check shape of this line, maybe something is off?
            gain_residual[tile_i, pol_i] = np.squeeze(gain_amp[tile_i, :] - gain_fit)

            # Fit for phase
            # TODO: Check the shape of gain_phase
            phase_use = np.unwrap(np.squeeze(gain_phase[tile_i, freq_use]))
            phase_params = np.polynomial.Polynomial.fit(freq_use, phase_use, pyfhd_config['cal_phase_degree_fit']).convert().coef
            cal["phase_params"][pol_i, tile_i, :] = phase_params
            phase_fit = np.zeros(obs['n_freq'])
            for di in range(pyfhd_config['cal_phase_degree_fit']):
                # TODO: Check shape
                phase_fit += phase_params[di] * np.arange(obs['n_freq'])**di
            gain_arr[tile_i, :] = gain_fit * np.exp(1j * phase_fit)
        # TODO: Check shape of gain
        cal['gain'][pol_i] = gain_arr

    # Cable Reflection Fitting
    if (cal_mode_fit):
        if (pyfhd_config['cal_reflection_mode_file']):
            logger.info('Using mwa calibration reflections fits from instrument_config/mwa_cable_reflection_coefficients.txt.')
            cable_reflections = np.loadtxt(Path(pyfhd_config['input-path'], 'instrument_config', 'mwa_cable_reflection_coefficients.txt'), skiprows=1).transpose()
            cable_length = cable_reflections[2]
            tile_ref_flag = np.minimum(np.maximum(np.zeros_like(cable_reflections[4]), cable_reflections[4]), np.ones_like(cable_reflections[4]))
            tile_mode_X = cable_reflections[5]
            tile_amp_X = cable_reflections[6]
            tile_phase_X = cable_reflections[7]
            tile_mode_Y = cable_reflections[8]
            tile_amp_Y = cable_reflections[9]
            tile_phase_Y = cable_reflections[10]

            # Modes in fourier transform units
            mode_i_arr = np.zeros((cal['n_pol'], obs['n_tile']))
            mode_i_arr[0, :] = tile_mode_X * tile_ref_flag
            mode_i_arr[1, :] = tile_mode_Y * tile_ref_flag

            amp_arr = np.vstack([tile_amp_X, tile_amp_Y])
            phase_arr = np.vstack[[tile_phase_X, tile_phase_Y]]

        elif (pyfhd_config['cal_reflection_mode_theory']):
            logger.info('Using theory calculation in nominal reflection mode calibration.')
            # Get the nominal tile lengths and velocity factors
            cable_length_data = np.loadtxt(Path(pyfhd_config['input-path'], 'intrument_config', 'mwa_cable_length.txt'), skiprows=1).transpose()
            cable_length = cable_length_data[2]
            cable_vf = cable_length_data[3]
            tile_ref_flag = np.minimum(np.maximum(np.zeros_like(cable_length_data[4]), cable_length_data[4]), np.ones_like(cable_length_data[4]))

            # Nominal Reflect Time
            reflect_time = (2 * cable_length) / (c * cable_vf)
            bandwidth = ((np.max(obs['baseline_info']['freq']) - np.min(obs['baseline_info']['freq'])) * obs['n_freq']) / (obs['n_freq'] - 1)
            # Modes in fourier transform units
            mode_i_arr = np.tile(bandwidth * reflect_time * tile_ref_flag, [cal["n_pol"], 1])

        elif (pyfhd_config['cal_reflection_mode_delay']):
            logger.info('Using calibration delay spectrum to calculate nominal reflection modes.')
            spec_mask = np.zeros(obs['n_freq'])
            spec_mask[freq_use] = 1
            freq_cut = np.where(spec_mask == 0)
            # IDL uses forward FFT by default
            spec_psf = np.abs(np.fft.fftn(spec_mask, norm='forward'))
            spec_inds = np.arange(obs['n_freq'] // 2)
            spec_psf = spec_psf[spec_inds]
            mode_test = np.zeros(obs['n_freq']  // 2)
            for pol_i in range(cal['n_pol']):
                for ti in range(tile_use[0].size):
                    tile_i = tile_use[0][ti]
                    spec0 = np.abs(np.fft.fftn(gain_residual[tile_i, pol_i]))
                    mode_test += spec0[spec_inds]
            psf_mask = np.zeros(obs['n_freq'] // 2)

            if (freq_cut[0].size > 0):
                psf_mask[np.where(spec_psf > (np.max(spec_psf) / 1000))] = 1
                # Replaces IDL smooth with edge_truncate
                psf_mask = uniform_filter(psf_mask, size = 5, mode = 'nearest')
                mask_i = np.nonzero(psf_mask)
                if (mask_i[0].size > 0):
                    mode_test[mask_i] = 0
            mode_i_arr = np.zeros((cal['n_pol'], obs['n_tile'])) + np.argmax(mode_test)

        # If you wish to implement the option to fit only certain cable lengths do that here
        # My suggestion to create a new argparse option set as an array of cable lengths
        # I would use the array as the cable lengths you want to only fit.
        # Loop through the array and use a flag array to multiply the mode_i_arr by 1 or 0
        # 0 will exclude the cable length from fitting, 1 will include it.
        # Do note you shouldn't do it if auto_ratio is defined and auto_ratio_calibration is enabled

        for pol_i in range(cal['n_pol']):
            # Divide the polyfit to reveal the residual cable reflections better
            gain_arr = og_gain_arr[pol_i] / cal['gain'][pol_i]
            for ti in range(tile_use[0].size):
                tile_i = tile_use[ti]
                mode_i = mode_i_arr[pol_i, tile_i]
                if (mode_i == 0):
                    continue
                else:
                    # Options to hyperresolve or fit the reflection modes/amp/phase given the nominal calculations
                    if (pyfhd_config['cal_reflection_hyperresolve']):
                        # start with nominal cable length
                        mode0 = mode_i
                        # overresolve the FT used for the fit (normal resolution would be dmode=1)
                        dmode = 0.05
                        # range around the central mode to test
                        nmodes = 101
                        # array of modes to try
                        modes = (np.arange(nmodes) - nmodes // 2) * dmode + mode0
                        # reshape for ease of computing
                        modes = rebin(modes, (nmodes, freq_use[0].size))

                        if (auto_ratio):
                            # Find tiles which will *not* be accidently coherent in their cable reflection in order to reduce bias
                            inds = np.where((obs['baseline_info']['tile_use']) & (mode_i_arr[pol_i, :] > 0) & (np.abs(mode_i_arr[pol_i,:] - mode_i)) > 0.01)
                            # mean over frequency for each tile
                            freq_mean = np.mean(auto_ratio[pol_i], axis = 1)
                            # normalized autos using each tile's freq mean
                            norm_autos = auto_ratio[pol_i] / rebin(np.transpose(freq_mean), (obs['n_freq'], obs['n_tile']))
                            # mean over all tiles which *are not* accidently coherent as a func of freq
                            incoherent_mean = np.mean(norm_autos[:, inds], axis=0)
                            # Residual and normalized (using incoherent mean) auto-correlation
                            resautos = (norm_autos[:, tile_i] / incoherent_mean) - np.mean(norm_autos[:, tile_i] / incoherent_mean)
                            gain_temp = rebin(np.transpose(np.squeeze(resautos[freq_use])), (nmodes, freq_use[0].size))
                        else:
                            # dimension manipulatio, add dim for mode fitting
                            # Subtract the mean so aliasing is reduced in the dft cable fitting
                            gain_temp = rebin(np.transpose(gain_arr[tile_i, freq_use]) - np.mean(gain_arr[tile_i, freq_use]), (nmodes, freq_use[0].size))
                        # freq_use matrix to multiply/collapse in fit
                        freq_mat = rebin(np.transpose(freq_use[0]), (nmodes, freq_use[0].size))
                        # Perform DFT of gains to test modes
                        test_fits = np.sum(np.exp(1j * 2 * np.pi/obs['n_freq'] * modes * freq_mat) * gain_temp, axis=-1)
                        # Pick out highest amplitude fit (mode_ind gives the index of the mode)
                        amp_use = np.max(np.abs(test_fits)) / freq_use[0].size
                        mode_ind = np.argmax(np.abs(test_fits))
                        # Phase of said fit
                        # TODO: change arctan if test_fits isn't complex (it should be though)
                        phase_use = np.arctan2(test_fits[mode_ind].imag, test_fits[mode_ind].real)
                        # The actual mode
                        mode_i = modes[0, mode_ind]

                        # Using the mode selected from the gains, optionally use the phase to find the amp and phase
                        if (auto_ratio):
                            # Find tiles which will not be accidently coherent in their cable reflection in order to reduce bias
                            inds = np.where(
                                obs['baseline_info']['tile_use'] & 
                                mode_i_arr[pol_i, :] > 0 & 
                                np.abs(mode_i_arr[pol_i, :] - mode_i) > 0.01
                            )
                            # TODO: check gain_arr indexing
                            residual_phase = np.arctan2(gain_arr[:, freq_use].imag, gain_arr[:, freq_use].real)
                            incoherent_residual_phase = residual_phase[tile_i, :] - np.mean(residual_phase[inds, :], axis=1)
                            test_fits = np.sum(np.exp(1j * 2 * np.pi/ obs['n_freq'] * mode_i * freq_use) * incoherent_residual_phase)
                            # Factor of 2 from fitting just the phase
                            amp_use = 2 * np.abs(test_fits) / freq_use[0].size
                            # Factor of pi/2 from just fitting the phase
                            phase_use = np.arctan2(test_fits.imag, test_fits.real) + np.pi/2
                    elif (pyfhd_config['cal_reflection_mode_file']):
                        # Use predetermined fits
                        # TODO check amp_arr and phase_arr indexing
                        amp_use = amp_arr[pol_i, tile_i]
                        phase_use = phase_arr[pol_i, tile_i]
                    else:
                        # Use nominal delay mode, but fit amplitude and phase of reflections
                        # TODO: check indexing of gain_arr
                        mode_fit = np.sum(np.exp(1j * 2 * np.pi / obs['n_freq'] * mode_i * freq_use) * np.squeeze(gain_arr[tile_i, freq_use]))
                        amp_use = np.abs(mode_fit) / freq_use[0].size
                        phase_use = np.arctan2(mode_fit.imag, mode_fit.real)
                    
                    gain_mode_fit = amp_use * np.exp(-1j * 2 * np.pi * (mode_i * np.arange(obs['n_freq']) / obs['n_freq']) + 1j * phase_use)
                    if (auto_ratio):
                        # Only fit for the cable reflection in the phases
                        cal['gain'][pol_i][tile_i, :] *= np.exp(1j * gain_mode_fit.imag)
                    else:
                        cal['gain'][pol_i][tile_i, :] *= 1 + gain_mode_fit 
                    # If you want to keep the mode params do that here
                    # TODO: check with Jack to see if this is needed
    return cal

def vis_cal_auto_fit(obs: dict, cal: dict, vis_auto : np.ndarray, vis_auto_model: np.ndarray, auto_tile_i: np.ndarray) -> dict:
    """
    TODO: _summary_

    Parameters
    ----------
    obs : dict
        The observation dictionary
    cal : dict
        The calibration dictionary
    vis_auto : np.ndarray
        TODO: _description_
    vis_auto_model : np.ndarray
        TODO: _description_
    auto_tile_i : np.ndarray
        TODO: _description_

    Returns
    -------
    cal: dict
        The calibration dictionary with the calibration fitted using autocorrelations
    """
    freq_i_use = np.nonzero(obs['baseline_info']['freq_use'])
    freq_i_flag = np.where(obs['baseline_info']['freq_use'] == 0)[0]
    # If the number of frequencies not being used is above 0, then ignore the frequencies surrounding them.
    if (freq_i_flag.size > 0):
        freq_flag = np.zeros(obs['n_freq'])
        freq_flag[freq_i_use] = 1
        for freq_i in range(freq_i_flag.size):
            minimum = max(0, freq_i_flag[freq_i] - 1)
            maximum = min(freq_i_flag.size - 1, freq_i_flag[freq_i] + 1)
            freq_flag[minimum : maximum] = 0
        freq_i_use = np.nonzero(freq_flag)
    # Vectorized loop for via_cal_auto_fit lines 45-55 in IDL
    auto_gain = np.sqrt(vis_auto*weight_invert(vis_auto_model))
    gain_cross = cal['gain']
    fit_slope = np.empty((cal['n_pol'], obs['n_tile']))
    fit_offset = np.empty_like(fit_slope)
    # Didn't vectorize as the polyfit won't be vectorized
    for pol_i in range(cal['n_pol']):
        for tile_i in range(obs['n_tile']):
            tile_i = auto_tile_i[tile_i]
            phase_cross_single = np.arctan2(gain_cross[pol_i, tile_i, :].imag, gain_cross[pol_i, tile_i, :].real)
            gain_auto_single = np.abs(auto_gain[pol_i, tile_i, :])
            gain_cross_single = np.abs(gain_cross[pol_i, tile_i, :])
            # linfit from IDL uses chi-square error calculations to do the linear fit, instead of least squares.
            # The polynomial fit uses least square method
            # TODO: Is there a good reason to use chi-square of least square in this case?
            fit_single = np.polynomial.Polynomial.fit(gain_auto_single[freq_i_use], gain_cross_single[freq_i_use]).convert().coef
            cal['gain'][pol_i, tile_i, :] = (gain_auto_single*fit_single[1] + fit_single[0]) * np.exp(1j * phase_cross_single)
            fit_slope[pol_i, tile_i] = fit_single[1]
            fit_offset[pol_i, tile_i] = fit_single[0]
    cal['auto_scale'] = np.sum(fit_slope, axis=0)
    cal['auto_params'] = np.empty([cal['n_pol'], cal['n_pol'], obs['n_tile']])
    cal['auto_params'][0, :, :] = fit_offset
    cal['auto_params'][1, :, :] = fit_slope
    return cal

def vis_calibration_apply(vis_arr: np.ndarray, obs: dict, cal: dict, vis_model_arr: np.ndarray, vis_weights: np.ndarray, logger: RootLogger) -> np.ndarray:
    """
    TODO: Docstring

    Parameters
    ----------
    vis_arr : np.ndarray
        _description_
    obs : dict
        _description_
    cal : dict
        _description_
    vis_model_arr : np.ndarray
        _description_
    vis_weights : np.ndarray
        _description_
    logger : RootLogger
        _description_

    Returns
    -------
    np.ndarray
        _description_
    """
    # tile numbering starts at 1
    tile_a_i = obs['baseline_info']['tile_a'] - 1
    tile_b_i = obs['baseline_info']['tile_b'] - 1
    # TODO: Check this is polarizations from vis_arr, should be 2 or 4
    n_pol_vis = vis_arr.shape[0]
    gain_pol_arr1 = [0,1,0,1]
    gain_pol_arr2 = [0,1,1,0]

    inds_rebin_arr = rebin(np.arange(obs['n_freq']), [obs['n_freq'], obs['n_baselines']], sample = True)
    inds_a = inds_rebin_arr + rebin(np.transpose(tile_a_i)* obs['n_freq'], [obs['n_freq'], obs['n_baselines']])
    inds_b = inds_rebin_arr + rebin(np.transpose(tile_b_i)* obs['n_freq'], [obs['n_freq'], obs['n_baselines']])

    # TODO: Vectorize
    for pol_i in range(n_pol_vis):
        gain_arr1 = cal['gain'][gain_pol_arr1[pol_i], : , :]
        gain_arr2 = cal['gain'][gain_pol_arr2[pol_i], : , :]
        # If you wish to add a way to invert the gain do that here with weight_invert
        vis_gain = gain_arr1[inds_a] * np.conjugate(gain_arr2[inds_b])
        vis_arr[pol_i, :, :] *= weight_invert(vis_gain)

    if (n_pol_vis == 4):
        if (vis_model_arr and vis_weights):
            # This if statement replaces vis_calibrate_crosspol_phase 
            # as this was the only place where the function was used
            # This code should calculate the phase fit between the X and Y
            # antenna polarizations.
            # TODO: Check shape of vis_arr
            # Use the xx flags (yy should be identitical at this point)
            weights_use = np.maximum(np.squeeze(vis_arr[0, obs['n_freq'], obs['n_baselines'], obs['n_times']]), np.zeros_like(np.squeeze(vis_arr[0, obs['n_freq'], obs['n_baselines'], obs['n_times']])))
            weights_use = np.minimum(weights_use, np.ones_like(weights_use))

            # Average the visbilities in time
            # TODO: check shape of vis_arr and adjust the rest accordingly
            vis_xy = np.squeeze(vis_arr[2, obs['n_freq'], obs['n_baselines'], obs['n_time']])
            # TODO: check where time axis ends up and adjust the axis parameter
            vis_xy = np.sum(vis_xy * weights_use, axis = -1)
            vis_yx = np.squeeze(vis_arr[3, obs['n_freq'], obs['n_baselines'], obs['n_times']])
            vis_yx = np.sum(vis_yx * weights_use, axis = -1)
            # TODO: check shape of vis_model_arr and adjust the rest accordingly
            model_xy = np.squeeze(vis_model_arr[2, obs['n_freq'], obs['n_baselines'], obs['n_time']])
            # TODO: check where time axis ends up and adjust the axis parameter
            model_xy = np.sum(model_xy * weights_use, axis = -1)
            model_yx = np.squeeze(vis_model_arr[3, obs['n_freq'], obs['n_baselines'], obs['n_times']])
            model_yx = np.sum(model_yx * weights_use, axis = -1)
            
            # Remove Zeros
            # TODO: Again check where time axis ends up and adjust
            weight = np.sum(weights_use, axis = -1)
            i_use = np.nonzero(weight)
            # TODO: Check IDL shapes for *_xy and *_yx as it uses a reform with 1 as its dimension which is weird (?)
            vis_xy = np.squeeze(vis_xy[i_use])
            vis_yx = np.squeeze(vis_yx[i_use])
            model_xy = np.squeeze(model_xy[i_use])
            model_yx = np.squeeze(model_yx[i_use])

            vis_sum = np.sum(np.conjugate(vis_xy) * model_xy) + np.sum(vis_yx * np.conjugate(model_yx))
            cross_phase = np.arctan2(vis_sum.imag, vis_sum.real)

            logger.info(f"Phase fit between X and Y antenna polarizations: {cross_phase}")

            cal["cross_phase"] = cross_phase
        
        vis_arr[2, : ,:] *= np.exp(1j * 0)
        vis_arr[3, :, :] *= np.exp(-1j * 0)

    return vis_arr, cal


def vis_baseline_hist(obs: dict, params: dict, vis_cal: np.ndarray, vis_model_arr: np.ndarray) -> dict:
    """
    TODO: Docstring

    Parameters
    ----------
    obs : dict
        _description_
    params : dict
        _description_
    vis_cal : np.ndarray
        _description_
    vis_model_arr : np.ndarray
        _description_

    Returns
    -------
    vis_baseline_hist : dict
        _description_
    """
    kx_arr = params['uu'] / obs['kpix']
    ky_arr = params['vv'] / obs['kpix']
    kr_arr = np.sqrt(kx_arr ** 2 + ky_arr ** 2)
    # TODO: Check what type of matrix multiply it is, guessed an outer because freq array is one dimensional
    dist_arr = np.outer(kr_arr, obs['baseline_info']['freq'])
    dist_hist, bins, dist_ri = histogram(dist_arr, min=obs['min_baseline'], max=obs['max_baseline'], bin_size=5.0)

    vis_res_ratio_mean = np.empty([obs['n_pol'], bins.size])
    vis_res_sigma = np.empty([obs['n_pol'], bins.size])
    for pol_i in range(obs['n_pol']):
        for bin_i in range(bins.size):
            if (dist_hist[bin_i] > 0):
                inds = dist_ri[dist_ri[bin_i] : dist_ri[bin_i+1]]
                # TODO: Check shape of vis_model_arr
                model_vals = vis_model_arr[pol_i, inds, :]
                wh_noflag = np.where(np.abs(model_vals) > 0)
                if (wh_noflag[0].size > 0):
                    inds = inds[wh_noflag]
                else:
                    continue
                # TODO: check shape of vis_cal and how inds should be used with it (might need flattening)
                vis_res_ratio_mean[pol_i, :] = np.mean(np.abs(vis_cal[pol_i, inds, :] - model_vals)) / np.mean(np.abs(model_vals))
                vis_res_sigma[pol_i, :] = np.sqrt(np.var(np.abs(vis_cal[pol_i, inds, :] - model_vals))) / np.mean(np.abs(model_vals))
            else:
                continue
    # In a change from FHD, the baseline_length is saved as dist_locs the array,
    # but dist_locs is only used for it's length, so I decided to take the length
    # of the bins array (which I used instead of dist_locs) and store this. This dict
    # will then get stored in the calibration dictionary when that gets saved.
    # If you wish to save it separately a call to h5py or deepdish and saving it separately
    # will work just fine
    return {
        'baseline_length' : bins.size,
        'vis_res_ratio_mean' : vis_res_ratio_mean,
        'vis_res_sigma' : vis_res_sigma
    }
    

def cal_auto_ratio_divide(obs: dict, cal: dict, vis_auto: np.ndarray, auto_tile_i: np.ndarray) -> Tuple[dict, np.ndarray]:
    """
    Create autos which are normalized via a reference to reveal antenna-dependent parameters
    (i.e. cable reflections). Then weight the crosses by their auto ratios in order to remove
    antenna-dependent parameters before creation of a global bandpass.

    Parameters
    ----------
    obs : dict
        The observation dictionary
    cal : dict
        The calibration dictionary
    vis_auto : np.ndarray        
        TODO: _description_
    auto_tile_i : np.ndarray
        TODO: _description_

    Returns
    -------
    (cal: dict, auto_ratio: np.ndarray)
        A Tuple which contains the cal_dcit with an updated gain with removed antenna-dependent parameters
        and the auto_ratio array containing the normalized reference (i.e. cable reflections)
    """
    auto_ratio = np.empty([cal['n_pol'], obs['n_tile'], obs['n_freq']])
    # TODO: Vectorize
    for pol_i in range(cal['n_pol']):
        # fhd_struct_init_cal puts the ref_antenna as 1 if it's not set, which is never appears to be
        v0 = vis_auto[pol_i, auto_tile_i[1], :]
        auto_ratio[pol_i, auto_tile_i, :] = np.sqrt(vis_auto[pol_i, np.arange(auto_tile_i.size), :] * weight_invert(v0))
        # TODO: check shape of gain
        cal['gain'][pol_i, :, :] = cal['gain'][pol_i, :, :] * weight_invert(auto_ratio[pol_i, : ,:])
    return cal, auto_ratio
    

def cal_auto_ratio_remultiply(obs: dict, cal: dict, auto_ratio: np.ndarray, auto_tile_i: np.ndarray) -> dict:
    """Reform the original calibration gains using the auto ratios

    Parameters
    ----------
    obs : dict
        The observation dictionary
    cal : dict
        The calibration dictionary
    auto_ratio : np.ndarray
        TODO:_description_
    auto_tile_i : np.ndarray
        TODO:_description_

    Returns
    -------
    cal: dict
        The calibration dictonary containing the reformed gain
    """
    # Replaced for loop in remultiply, this should remultiply by the auto_ratios
    # TODO: check shape of cal['gain']
    cal['gain'][0: cal['n_pol'], auto_tile_i, :] = cal['gain'][0: cal['n_pol'], auto_tile_i, :] * np.abs(auto_ratio[0 : cal['n_pol'], auto_tile_i, :])
    return cal


def calculate_adaptive_gain(gain_list, convergence_list, iter, base_gain, final_convergence_estimate = None):
    """
    TODO: Docstring
    [summary]

    Parameters
    ----------
    gain_list : [type]
        [description]
    convergence_list : [type]
        [description]
    iter : [type]
        [description]
    base_gain : [type]
        [description]
    final_convergence_estimate : [type], optional
        [description], by default None
    """
    if iter > 2:
        # To calculate the best gain to use, compare the past gains that have been used
        # with the resulting convergences to estimate the best gain to use.
        # Algorithmically, this is a Kalman filter.
        # If forward modeling proceeds perfectly, the convergence metric should
        # asymptotically approach a final value.
        # We can estimate that value from the measured changes in convergence
        # weighted by the gains used in each previous iteration.
        # For some applications such as calibration this may be known in advance.
        # In calibration, it is expressed as the change in a
        # value, in which case the final value should be zero.
        if final_convergence_estimate is None:
            est_final_conv = np.zeros(iter - 1)
            for i in range(iter - 1):
                final_convergence_test = ((1 + gain_list[i]) * convergence_list[i + 1] - convergence_list[i]) / gain_list[i]
                # The convergence metric is strictly positive, so if the estimated final convergence is
                # less than zero, force it to zero.
                est_final_conv[i] = np.max((0, final_convergence_test))
            # Because the estimate may slowly change over time, only use the most recent measurements.
            final_convergence_estimate = np.median(est_final_conv[max(iter - 5, 0):])
        last_gain = gain_list[iter - 1]
        last_conv = convergence_list[iter - 2]
        new_conv = convergence_list[iter - 1]
        # The predicted convergence is the value we would get if the new model calculated
        # in the previous iteration was perfect. Recall that the updated model that is
        # actually used is the gain-weighted average of the new and old model,
        # so the convergence would be similarly weighted.
        predicted_conv = (final_convergence_estimate * last_gain + last_conv) / (base_gain + last_gain)
        # If the measured and predicted convergence are very close, that indicates
        # that our forward model is accurate and we can use a more aggressive gain
        # If the measured convergence is significantly worse (or better!) than predicted,
        # that indicates that the model is not converging as expected and
        # we should use a more conservative gain.
        delta = (predicted_conv - new_conv) / ((last_conv - final_convergence_estimate) / (base_gain + last_gain))
        new_gain = 1 - abs(delta)
        # Average the gains to prevent oscillating solutions.
        new_gain = (new_gain + last_gain) / 2
        # For some reason base_gain can be a numpy float in testing so putting in a tuple solves this.
        gain = np.max((base_gain / 2, new_gain))

    else:
        gain = base_gain
    gain_list[iter] = gain

    return gain