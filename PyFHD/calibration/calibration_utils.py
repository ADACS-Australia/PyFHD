import numpy as np
from typing import Tuple
from logging import RootLogger
from PyFHD.pyfhd_tools.pyfhd_utils import resistant_mean, weight_invert
from copy import deepcopy
from astropy.io import fits
from astropy.constants import c
from pathlib import Path
from scipy.signal import convolve
from astropy.convolution import Box1DKernel


def vis_extract_autocorr(obs: dict, vis_arr: np.array, time_average = True, auto_tile_i = None) -> Tuple[np.array, np.array]:
    """
    TODO: Docstring

    Parameters
    ----------
    obs : dict
        The dictionary generated by PyFHD containing metadata and data from the observation
    vis_arr : np.array
        The visibility array
    time_average : bool, optional
        _description_, by default True
    auto_tile_i : _type_, optional
        _description_, by default None

    Returns
    -------
    Tuple[autocorr: np.array, auto_tile_i: np.array]
        The first array is the auto-correlation visibilities and the second array is the unique tile values
    """
    # TODO: check if tile_A and tile_B 2D
    autocorr_i = np.where(obs["baseline_info"]["tile_A"] == obs["baseline_info"]["tile_B"])[0]
    if (autocorr_i[0].size > 0):
        auto_tile_i = obs["baseline_info"]["tile_A"][autocorr_i] - 1
        auto_tile_i_single = np.unique(auto_tile_i)
        auto_corr = np.zeros(obs["n_pol"])
        for pol_i in range(obs["n_pol"]):
            # TODO: check vis_arr shape again, compare against IDL
            auto_vals = vis_arr[pol_i, :, autocorr_i]
            if (time_average):
                auto_single = np.zeros([auto_tile_i_single.size, obs["n_freq"]])
                time_inds = np.where(obs["baseline_info"]["time_use"])
                for tile_i in range(time_inds[0].size):
                    baseline_i = np.where(auto_tile_i == auto_tile_i_single[tile_i])
                    baseline_i = baseline_i[time_inds]
                    if (time_inds[0].size > 1): 
                        # TODO: Replace extract_subarray
                        auto_single[tile_i, :] = np.sum(extract_subarray(auto_vals, np.arange(obs["n_freq"]), baseline_i)) / time_inds[0].size
                    else:
                        # TODO: Replace extract_subarray
                        auto_single[tile_i, :] = extract_subarray(auto_vals, np.arange(obs["n_freq"]), baseline_i)
                auto_vals = auto_single
            # TODO: Get size of auto_vals or do a python list of numpy arrays
            auto_corr[pol_i] = auto_vals
        if (time_average):
            auto_tile_i = auto_tile_i_single
        return auto_corr, auto_tile_i
    else:
        # Return auto_corr as 0 and auto_tile_i as an empty array
        return np.zeros(1), np.zeros(0)

def vis_cal_auto_init(obs : dict, cal : dict, vis_arr: np.array, vis_model_arr: np.array, vis_auto: np.array, vis_auto_model: np.array, auto_tile_i: np.array) -> np.array:
    """
    TODO: Docstring

    Parameters
    ----------
    obs : dict
        _description_
    cal : dict
        _description_
    vis_arr : np.array
        _description_
    vis_model_arr : np.array
        _description_
    vis_auto : np.array
        _description_
    vis_auto_model : np.array
        _description_
    auto_tile_i : np.array
        _description_

    Returns
    -------
    auto_gain : np.array
        _description_
    """
    # TODO: This should be a list, or ideally an numpy array with a known shape, change this line to reflect this
    auto_scale = np.zeros(cal["n_pol"])
    freq_i_use = np.where(obs["baseline_info"]["freq_use"])
    for pol_i in range(cal["n_pol"]):
        res_mean_data = resistant_mean(vis_arr[pol_i, :, freq_i_use], 2)
        res_mean_model = resistant_mean(vis_model_arr[pol_i, :, freq_i_use], 2)
        auto_scale[pol_i] = np.sqrt(res_mean_data / res_mean_model)
    # TODO: This should be a list, or ideally an numpy array with a known shape, change this line to reflect this
    auto_gain = np.zeros(cal["n_pol"], dtype=np.complex128)
    for pol_i in range(cal["n_pol"]):
        gain_arr = np.zeros([obs["n_tile"], obs["n_freq"]], dtype=np.complex128)
        for freq_i in range(obs["n_freq"]):
            for tile_i in range(auto_tile_i.size):
                # TODO: Check size of gain_single in FHD and compare against what's here
                gain_arr[auto_tile_i[tile_i], freq_i] = np.sqrt(vis_auto[pol_i, tile_i, freq_i] * weight_invert(vis_model_arr[pol_i, tile_i, freq_i]))
        gain_arr *= auto_scale[pol_i] * weight_invert(np.mean(gain_arr))
        gain_arr[np.isnan(gain_arr)] = 1
        gain_arr[np.where(gain_arr) <= 0] = 1
        auto_gain[pol_i] = gain_arr
    return auto_gain

def vis_calibration_flag(obs: dict, cal: dict, params: dict, pyfhd_config: dict, logger: RootLogger) -> dict:
    """
    TODO: Docstring

    Parameters
    ----------
    obs : dict
        _description_
    cal : dict
        _description_
    pyfhd_config : dict
        The configuration dictionary for PyFHD given at the start of the run
    logger : RootLogger
        PyFHD's logger for displaying errors and info to the log files

    Returns
    -------
    obs: dict
        _description_
    """
    amp_sigma_threshold = 5
    amp_threshold = 2
    phase_sigma_threshold = 5
    for pol_i in range(cal["n_pol"]):
        tile_use_i = np.where(obs["baseline_info"]["tile_use"])
        freq_use_i = np.where(obs["baseline_info"]["freq_use"])
        # TODO: adjust depending on size given by vis_cal_auto_init
        gain = cal["gain"][pol_i]
        phase = np.arctan2(gain.imag, gain.real)
        amp = np.abs(gain)

        # first flag based on overall amplitude
        # extract_subarray is not being used as it was FHD's way of taking the fact that
        # IDL's indexing can be weird and won't allow to index the resut
        # TODO: May need to adjust the indexing to match IDL as tile_use_i and freq_use_i use np.where on gain, which will be multidimensional as well
        amp_sub = amp[tile_use_i[0],:][: , freq_use_i[0]]
        gain_freq_fom = np.std(amp_sub[:, 0: freq_use_i[0].size])
        amp_sub2 = amp_sub[tile_use_i[0], :]
        # Calculate the y values from a polynomial fit and keep the standard deviation of the error in gain_tile_fom
        amp_sub2_fit = np.polynomial.polynomial.polyval(freq_use_i[0],np.polynomial.Polynomial.fit(freq_use_i[0], amp_sub2, deg = pyfhd_config["cal_amp_degree_fit"]).convert().coef)
        gain_tile_fom = np.std(amp_sub2 - amp_sub2_fit)
        gain_tile_avg = np.median(amp_sub2)
        gain_freq_fom[np.isnan(gain_freq_fom)] = 0
        gain_tile_fom[np.isnan(gain_tile_fom)] = 0
        freq_cut_i = np.where(gain_freq_fom == 0)
        freq_uncut_i = np.nonzero(gain_freq_fom)
        if (freq_cut_i[0].size > 0):
            obs["baseline_info"]["freq_use"][freq_use_i][0][freq_cut_i] = 0
        tile_cut_i = np.where(gain_tile_fom == 0)
        tile_uncut_i = np.nonzero(gain_tile_fom)
        if (tile_cut_i[0].size > 0):
            obs["baseline_info"]["tile_use"][tile_use_i][0][tile_cut_i] = 0
        if (freq_uncut_i[0].size > 0 or tile_uncut_i[0].size):
            # TODO: Check message is correct
            logger.error("The frequency and tile flagging inside claibration found some values not detected in previous flagging or calibration")
        
        n_addl_cut = max(freq_cut_i[0].size + tile_cut_i[0].size, 1)
        n_cut = freq_cut_i[0].size + tile_cut_i[0].size
        iter = 0
        while n_addl_cut > 0 and iter < 3:
            gain_freq_sigma = np.std(gain_freq_fom[freq_uncut_i])
            gain_tile_sigma = np.std(gain_tile_fom[tile_uncut_i])
            freq_cut_test = (gain_freq_fom - np.median(gain_tile_fom[freq_uncut_i]) - amp_sigma_threshold * gain_freq_sigma) > 0
            # TODO: Check size of freq_cut_i
            freq_cut_i = np.where(freq_cut_test)
            tile_cut_test1 = (gain_tile_fom - np.median(gain_tile_fom[tile_uncut_i]) - amp_sigma_threshold * gain_tile_sigma) > 0
            tile_cut_test2 = (gain_tile_avg < np.median(gain_tile_avg) / amp_threshold) or (gain_tile_avg > np.median(gain_tile_avg) * amp_threshold)
            # TODO: Check size of tile_cut_i
            tile_cut_i = np.where(tile_cut_test1 or tile_cut_test2)
            n_addl_cut = (freq_cut_i[0].size + tile_cut_i[0]) - n_cut
            n_cut = freq_cut_i[0].size + tile_cut_i[0].size
            iter+=1
        if (freq_cut_i[0].size) > 0:
            obs["baseline_info"]["freq_use"][freq_use_i[freq_cut_i]] = 0
        if (tile_cut_i[0].size) > 0:
            obs["baseline_info"]["tile_use"][tile_use_i[tile_cut_i]] = 0

        # Reset freq_use_i and tile_use_i for flagging based on phase
        tile_use_i = np.where(obs["baseline_info"]["tile_use"])
        freq_use_i = np.where(obs["baseline_info"]["freq_use"])

        # Start flagging based on phase
        phase_sub = phase[tile_use_i[0], :][:, freq_use_i[0]]
        phase_slope_arr = np.empty(tile_use_i[0].size)
        phase_sigma_arr = np.empty(tile_use_i[0].size)
        for tile_i in range(tile_use_i[0].size):
            phase_use = np.unwrap(phase_sub[tile_i, :])
            fi_use2 = np.arange(freq_use_i[0].size)
            # TODO: Check the size, but should be a 1D array
            phase_use2 = phase_use[fi_use2]
            phase_params = np.polynomial.polynomial.Polynomial.fit(freq_use_i[fi_use2], phase_use2, deg=pyfhd_config["cal_phase_degree_fit"])
            phase_params = phase_params.convert()
            phase_fit = np.polynomial.polynomial.polyval(freq_use_i[fi_use2], phase_params.coef)
            phase_sigma2 = np.std(phase_use2 - phase_fit)
            # TODO: Check coefficients are the same shape
            phase_slope_arr[tile_i] = phase_params[1]
            phase_sigma_arr[tile_i] = phase_sigma2
        iter = 0
        n_addl_cut = 1
        n_cut = 0
        while n_addl_cut > 0 and iter < 3:
            slope_sigma = np.std(phase_slope_arr)
            tile_cut_test1 = (np.abs(phase_slope_arr) - np.median(np.abs(phase_slope_arr))) > phase_sigma_threshold * slope_sigma
            tile_cut_test2 = (phase_sigma_arr - np.median(phase_sigma_arr)) > phase_sigma_threshold * np.std(phase_sigma_arr)
            # TODO: Check size of tile_cut_i
            tile_cut_i = np.where(tile_cut_test1 or tile_cut_test2)
            n_addl_cut = tile_cut_i[0].size - n_cut
            n_cut = tile_cut_i[0].size
            iter += 1
        if (tile_cut_i[0].size > 0):
            obs["baseline_info"]["tile_use"][tile_use_i[tile_cut_i]] = 0
    # Return the obs with an updated baseline_info on the use of tiles and frequency
    return obs

def transfer_bandpass(obs: dict, params: dict, cal: dict, pyfhd_config: dict, logger: RootLogger) -> Tuple[dict, dict]:
    # TODO: Get bandpass from fits file and process the data_array
    cal_bandpass = {}
    try:  
        calfits = fits.open(Path(pyfhd_config['input_path'], pyfhd_config["cal_bp_transfer"]))
    except FileNotFoundError as e:
        logger.error(f"{pyfhd_config['cal_bp_transfer']} file wasn't found, skipping calibration bandpass transfer")
        return {}, {}
    cal_remainder = deepcopy(cal)
    cal_remainder["gain"][0 : cal["n_pol"]] = cal["gain"][0 : cal["n_pol"]] / cal_bandpass["gain"][0 : cal["n_pol"]]
    return cal_bandpass, cal_remainder

def vis_cal_bandpass(obs: dict, cal: dict, params: dict, pyfhd_config: dict, logger: RootLogger) -> Tuple[dict, dict]:
    """
    TODO: Docstring

    Parameters
    ----------
    obs : dict
        The observation data given to PyFHD
    cal : dict
        The calibration dictionary containing the data from the calibration
    params : dict
        The PyFHD params containing uu, ww, vv
    pyfhd_config : dict
        The config used to start PyFHD containing config for calibration
    logger : RootLogger
        PyFHD's logger

    Returns
    -------
    (cal_bandpass, cal_remainder) : Tuple[dict, dict]
        The bandpass gain dictonary and the remainder cable gain dictionary
    """
    freq_use = np.nonzero(obs["baseline_info"]["freq_use"])[0]
    tile_use = np.nonzero(obs["baseline_info"]["tile_use"])[0]
    n_pol = cal["gain"].size
    # Set a flag for global bandpass, will turn true if too many tiles are flagged
    global_bandpass = False

    # Initialize cal_bandpass and cal_remainder and transfer them in, if a file has been set (fits only supported right now)
    if (pyfhd_config["cal_bp_transfer"] is not None):
        # TODO: Finish transfer_bandpass (code to translate will be in calfits_read.pro)
        cal_bandpass, cal_remainder = transfer_bandpass(obs, params, cal, pyfhd_config, logger)
        if (len(cal_bandpass.keys()) != 0 and len(cal_remainder.keys()) != 0):
            logger.info(f"Calibration Bandpass FITS file {pyfhd_config['cal_bp_transfer']} transferred in for cal_bandpass and cal_remainder")
            return cal_bandpass, cal_remainder
    cal_bandpass = deepcopy(cal)
    cal_remainder = deepcopy(cal)
     # These replace gain_arr_ptr_2 & 3 from FHD with better names
    cal_bandpass_gain = np.empty(n_pol)
    cal_remainder_gain = np.empty(n_pol)

    if (pyfhd_config["cable_bandpass_fit"]):
        # Using preexisting file to extract information about which tiles have which cable length
        cable_len = np.loadtxt(Path(pyfhd_config["input"], pyfhd_config["cable-reflection-coefficients"]), skiprows=1)[:, 2].flatten()
        # Taking tile information and cross-matching it with the nonflagged tiles array, resulting in nonflagged tile arrays grouped by cable length
        cable_length_ref = np.unique(cable_len)
        tile_use_arr = [] * cable_length_ref.size
        for cable_i in range(cable_length_ref.size):
            tile_use_arr[cable_i] = np.where((obs["baseline_info"]["tile_use"]) & (cable_len == cable_length_ref[cable_i]))
            if (tile_use_arr[0].size == 0):
                logger.warning("Too Many flagged tiles to implement bandpass cable averaging, using global bandpass.")
                global_bandpass = True
        # n_freq x 13 array. columns are frequency, 90m xx, 90m yy, 150m xx, 150m yy, 230m xx, 230m yy, 320m xx, 320m yy, 400m xx, 400m yy, 524m xx, 524m yy
        bandpass_arr = np.zeros(obs["n_freq"], cal["n_pol"] * cable_length_ref.size + 1)
        bandpass_arr[:, 0] = cal["freq"]
        bandpass_col_count = 1
        for cable_i in range(cable_length_ref.size):
            # This is an option to calibrate over all tiles to find the 'global' bandpass. It will be looped over by the number
            # of cable lengths, and will redo the same calculation everytime. It is inefficient, but effective.
            if global_bandpass:
                tile_use_cable = tile_use
            else:
                tile_use_cable = tile_use_arr[cable_i]

            for pol_i in range(cal["n_pol"]):
                gain = cal["gain"][pol_i]
                # gain2 is a temporary variable used in place of the gain array for an added layer of safety
                if (cable_i == 0 and pol_i == 0):
                    gain2 = np.zeros((gain.shape[0], gain[1], cal["n_pol"]), dtype = np.complex128)
                # Only use gains from unflagged tiles and frequencies, and calculate the amplitude and phase
                gain_use = gain[tile_use_cable,:][: , freq_use]
                amp = np.abs(gain_use)
                # amp2 is a temporary variable used in place of the amp array for an added layer of safety
                amp2 = np.zeros(tile_use_cable.size, freq_use.size)
                # This is the normalization loop for each tile. If the mean of gain amplitudes over all frequencies is nonzero, then divide
                # the gain amplitudes by that number, otherwise make the gain amplitudes zero.
                for tile_i in range(tile_use_cable.size):
                    res_mean = resistant_mean(amp[tile_i, :], 2)
                    if res_mean != 0:
                        amp2[tile_i, :] = amp[tile_i, :] / res_mean
                    else:
                        amp2[tile_i, :] = 0
                # This finds the normalized gain amplitude mean per frequency over all tiles, which is the final bandpass per cable group.
                bandpass_single = np.empty((freq_use.size, tile_use.size))
                # If this is slow, resistant_mean can be vectorized
                for f_i in range(freq_use.size):
                    bandpass_single[f_i, :] = resistant_mean(amp2[:, f_i], 2)
                # Want iterative to start at 1 (to not overwrite freq) and store final bandpass per cable group.
                bandpass_arr[freq_use, bandpass_col_count] = bandpass_single
                bandpass_col_count += 1
                # Fill temporary variable gain2, set equal to final bandpass per cable group for each tile that will use that bandpass. 
                gain2[tile_use_cable, freq_use, pol_i] = bandpass_single
                # For the last bit at the end of the cable
                if cable_i == cable_length_ref.size - 1:
                    # Set gain3 to the input gains
                    gain3 = deepcopy(cal["gain"])
                    # Set what will be passed back as the output gain as the final bandpass per cable type.
                    gain2_input = np.squeeze(gain2[:, : , pol_i])
                    cal_bandpass_gain[pol_i] = gain2_input
                    # Set what will be passed back as the residual as the input gain divided by the final bandpass per cable type.
                    gain3[0: obs["n_tile"], freq_use] /= gain2_input[0 : obs["n_tile"], freq_use]
                    cal_remainder_gain[pol_i] = gain3
        # Add Levine Memo bandpass to the gain solutions here if you wish
    else:
        for pol_i in range(cal["n_pol"]):
            gain = cal["gain"][pol_i]
            gain_use = gain[tile_use_cable,:][: , freq_use]
            amp = np.abs(gain_use)
            amp2 = np.zeros(tile_use.size, freq_use.size)
            for tile_i in range(tile_use.size):
                res_mean = resistant_mean(amp[tile_i, :], 2)
                if res_mean:
                    amp2[tile_i, : ] = amp[tile_i , : ] / res_mean
                else:
                    amp2[tile_i, : ] = 0
            bandpass_single = np.empty((freq_use.size, tile_use.size))
            # If this is slow, resistant_mean can be vectorized
            for f_i in range(freq_use.size):
                bandpass_single[f_i, :] = resistant_mean(amp2[: ,f_i], 2)
            bandpass_arr[freq_use, pol_i + 1] = bandpass_single
            # Work out the gain for the bandpass
            gain2 = np.zeros(gain.shape, dtype = np.complex128)
            gain2[0 : tile_use.size, freq_use] = bandpass_single
            cal_bandpass_gain[pol_i] = gain2
            # Work out the gain for the remaider of the cable
            gain3 = gain
            gain3[0: tile_use.size, freq_use] /= bandpass_single
            cal_remainder_gain[pol_i] = gain3
    cal_bandpass["gain"] = cal_bandpass_gain
    cal_remainder["gain"] = cal_remainder_gain
    return cal_bandpass, cal_remainder

def vis_cal_polyfit(obs: dict, cal: dict, pyfhd_config: dict, logger: RootLogger) -> dict:
    if (pyfhd_config['cal_reflection_mode_theory'] or 
        pyfhd_config['cal_reflection_mode_file'] or 
        pyfhd_config['cal_reflection_mode_delay'] or
        pyfhd_config['cal_reflection_hyperresolve']
    ):
        if (pyfhd_config['cal_reflection_mode_theory'] and abs(pyfhd_config['cal_reflection_mode_theory']) > 1):
            cal_mode_fit = pyfhd_config['cal_reflection_mode_theory']
        else:
            cal_mode_fit = 1
    freq_use = np.where(obs['baseline_info']['freq_use'])
    tile_use = np.where(obs['baseline_info']['tile_use'])

    # If the amp_degree or phase_degree weren't used, then apply the defaults
    if (not pyfhd_config['cal_amp_degree_fit']):
        pyfhd_config['cal_amp_degree_fit'] = 2
    if (not pyfhd_config['cal_phase_degree_fit']):
        pyfhd_config['cal_phase_degree_fit'] = 1

    # If you wish to find any steps that are outliers beyond 5sigma, and remove them add that code here.
    # The cal_step_fit option isn't in the eor_defaults_wrapper or defined in the FHD dictionary.

    # Polynomial fitting over the frequency band
    gain_residual = np.empty((obs['n_tile'], cal['n_pol']))
    # create amp_params with the shape of (n_pol, n_tile, amp_degree + 1)
    cal['amp_params'] = np.empty((cal['n_pol'], obs['n_tile'], pyfhd_config["cal_amp_degree_fit"] + 1))
    cal['phase_params'] = np.empty((cal['n_pol'], obs['n_tile'], pyfhd_config["cal_phase_degree_fit"] + 1))
    for pol_i in range(cal['n_pol']):
        gain_arr = cal['gain'][pol_i]
        gain_amp = np.abs(gain_arr)
        gain_phase = np.arctan2(gain_arr.imag, gain_arr.real)
        for tile_i in range(obs['n_tile']):
            gain = np.squeeze(gain_amp[tile_i, freq_use])
            # Fit for amplitude
            fit_params = np.polynomial.Polynomial.fit(freq_use, gain, deg = pyfhd_config["cal_amp_degree_fit"]).convert().coef
            cal['amp_params'][pol_i, tile_i, :] = fit_params
            gain_fit = np.zeros(obs['n_freq'])
            for di in range(pyfhd_config['cal_amp_degree_fit']):
                gain_fit += fit_params[di, :, :] * np.arange(obs['n_freq'])**di
            # If you wish to fit pre and post digital gain jump separately for highband MWA data, do that here
            # TODO: Check size of this line, maybe something is off?
            gain_residual[tile_i, pol_i] = np.squeeze(gain_amp[tile_i, :] - gain_fit)

            # Fit for phase
            # TODO: Check the shape of gain_phase
            phase_use = np.unwrap(np.squeeze(gain_phase[tile_i, freq_use]))
            phase_params = np.polynomial.Polynomial.fit(freq_use, phase_use, pyfhd_config['cal_phase_degree_fit']).convert().coef
            cal["phase_params"][pol_i, tile_i, :] = phase_params
            phase_fit = np.zeros(obs['n_freq'])
            for di in range(pyfhd_config['cal_phase_degree_fit']):
                # TODO: Check shape
                phase_fit += phase_params[di] * np.arange(obs['n_freq'])**di
            gain_arr[tile_i, :] = gain_fit * np.exp(1j * phase_fit)
        # TODO: Check shape of gain
        cal['gain'][pol_i] = gain_arr

    # Cable Reflection Fitting
    if (cal_mode_fit):
        if (pyfhd_config['cal_reflection_mode_file']):
            logger.info('Using mwa calibration reflections fits from instrument_config/mwa_cable_reflection_coefficients.txt.')
            cable_reflections = np.loadtxt(Path(pyfhd_config['input-path'], 'instrument_config', 'mwa_cable_reflection_coefficients.txt'), skiprows=1).transpose()
            cable_length = cable_reflections[2]
            tile_ref_flag = np.minimum(np.maximum(np.zeros_like(cable_reflections[4]), cable_reflections[4]), np.ones_like(cable_reflections[4]))
            tile_mode_X = cable_reflections[5]
            tile_amp_X = cable_reflections[6]
            tile_phase_X = cable_reflections[7]
            tile_mode_Y = cable_reflections[8]
            tile_amp_Y = cable_reflections[9]
            tile_phase_Y = cable_reflections[10]

            # Modes in fourier transform units
            mode_i_arr = np.zeros((cal['n_pol'], obs['n_tile']))
            mode_i_arr[0, :] = tile_mode_X * tile_ref_flag
            mode_i_arr[1, :] = tile_mode_Y * tile_ref_flag

            amp_arr = np.vstack([tile_amp_X, tile_amp_Y])
            phase_arr = np.vstack[[tile_phase_X, tile_phase_Y]]

        elif (pyfhd_config['cal_reflection_mode_theory']):
            logger.info('Using theory calculation in nominal reflection mode calibration.')
            # Get the nominal tile lengths and velocity factors
            cable_length_data = np.loadtxt(Path(pyfhd_config['input-path'], 'intrument_config', 'mwa_cable_length.txt'), skiprows=1).transpose()
            cable_length = cable_length_data[2]
            cable_vf = cable_length_data[3]
            tile_ref_flag = np.minimum(np.maximum(np.zeros_like(cable_length_data[4]), cable_length_data[4]), np.ones_like(cable_length_data[4]))

            # Nominal Reflect Time
            reflect_time = (2 * cable_length) / (c * cable_vf)
            bandwidth = ((np.max(obs['baseline_info']['freq']) - np.min(obs['baseline_info']['freq'])) * obs['n_freq']) / (obs['n_freq'] - 1)
            # Modes in fourier transform units
            mode_i_arr = np.tile(bandwidth * reflect_time * tile_ref_flag, [cal["n_pol"], 1])

        elif (pyfhd_config['cal_reflection_mode_delay']):
            logger.info('Using calibration delay spectrum to calculate nominal reflection modes.')
            spec_mask = np.zeros(obs['n_freq'])
            spec_mask[freq_use] = 1
            freq_cut = np.where(spec_mask == 0)
            # IDL uses forward FFT by default
            spec_psf = np.abs(np.fft.fftn(spec_mask, norm='forward'))
            spec_inds = np.arange(obs['n_freq'] // 2)
            spec_psf = spec_psf[spec_inds]
            mode_test = np.zeros(obs['n_freq']  // 2)
            for pol_i in range(cal['n_pol']):
                for ti in range(tile_use[0].size):
                    tile_i = tile_use[0][ti]
                    spec0 = np.abs(np.fft.fftn(gain_residual[tile_i, pol_i]))
                    mode_test += spec0[spec_inds]
            psf_mask = np.zeros(obs['n_freq'] // 2)

            if (freq_cut[0].size > 0):
                psf_mask[np.where(spec_psf > (np.max(spec_psf) / 1000))] = 1
                psf_mask = convolve(psf_mask, Box1DKernel(5), mode = 'valid')


def vis_cal_combine(): 
    pass

def vis_cal_auto_fit():
    pass

def vis_cal_subtract():
    pass

def vis_calibration_apply():
    pass

def calculate_adaptive_gain(gain_list, convergence_list, iter, base_gain, final_convergence_estimate = None):
    """
    TODO: Docstring
    [summary]

    Parameters
    ----------
    gain_list : [type]
        [description]
    convergence_list : [type]
        [description]
    iter : [type]
        [description]
    base_gain : [type]
        [description]
    final_convergence_estimate : [type], optional
        [description], by default None
    """
    if iter > 2:
        # To calculate the best gain to use, compare the past gains that have been used
        # with the resulting convergences to estimate the best gain to use.
        # Algorithmically, this is a Kalman filter.
        # If forward modeling proceeds perfectly, the convergence metric should
        # asymptotically approach a final value.
        # We can estimate that value from the measured changes in convergence
        # weighted by the gains used in each previous iteration.
        # For some applications such as calibration this may be known in advance.
        # In calibration, it is expressed as the change in a
        # value, in which case the final value should be zero.
        if final_convergence_estimate is None:
            est_final_conv = np.zeros(iter - 1)
            for i in range(iter - 1):
                final_convergence_test = ((1 + gain_list[i]) * convergence_list[i + 1] - convergence_list[i]) / gain_list[i]
                # The convergence metric is strictly positive, so if the estimated final convergence is
                # less than zero, force it to zero.
                est_final_conv[i] = np.max((0, final_convergence_test))
            # Because the estimate may slowly change over time, only use the most recent measurements.
            final_convergence_estimate = np.median(est_final_conv[max(iter - 5, 0):])
        last_gain = gain_list[iter - 1]
        last_conv = convergence_list[iter - 2]
        new_conv = convergence_list[iter - 1]
        # The predicted convergence is the value we would get if the new model calculated
        # in the previous iteration was perfect. Recall that the updated model that is
        # actually used is the gain-weighted average of the new and old model,
        # so the convergence would be similarly weighted.
        predicted_conv = (final_convergence_estimate * last_gain + last_conv) / (base_gain + last_gain)
        # If the measured and predicted convergence are very close, that indicates
        # that our forward model is accurate and we can use a more aggressive gain
        # If the measured convergence is significantly worse (or better!) than predicted,
        # that indicates that the model is not converging as expected and
        # we should use a more conservative gain.
        delta = (predicted_conv - new_conv) / ((last_conv - final_convergence_estimate) / (base_gain + last_gain))
        new_gain = 1 - abs(delta)
        # Average the gains to prevent oscillating solutions.
        new_gain = (new_gain + last_gain) / 2
        # For some reason base_gain can be a numpy float in testing so putting in a tuple solves this.
        gain = np.max((base_gain / 2, new_gain))

    else:
        gain = base_gain
    gain_list[iter] = gain

    return gain